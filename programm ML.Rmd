---
title: "PRACTICAL MACHINE LEARNING COURSERA PROJECT"
author: "cedric gaillard"
date: "Wednesday, October 21, 2015"
output: html_document
---


The goal of this project is to “predict the manner in which they did the exercise.”

For this project, I use the library following :
- Caret
- e1071
- ggplot2
- RandomForest
- rmarkdown

Five diffrents ways, as described in the study, were according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.

We use the following study:

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

We want predicted the appropriate activity quality with this 5 classes by processing data collected by accelerometers on the belt, forearm, arm, and dumbell of the participants with machine learning technical.

1. IMPORT DATA

We import the training and the test data in stating the decimals according regional setting.
#import data
> df_training <- read.csv2("C:/Users/Cedric/Downloads/pml-training.csv", sep=",",dec=".",na.strings=c("NA",""), header=TRUE)
> df_testing <- read.csv2("C:/Users/Cedric/Downloads/pml-training.csv", sep=",",dec=".",na.strings=c("NA",""), header=TRUE)

As there is many blanks,I decided to remplace this cells by "NA"" in importing the data with the option na.strings=c("NA","").

2. CHOICE OF FEATURES

We note there are many NA values. We count the number by colums :
#Count of NA
> NumberNA <- function(x) {as.vector(apply(x, 2, function(x) length(which(is.na(x)))))}
> colNA=NumberNA(df_training)

101 colums have 19216 values "NA". Many of this column are some calculated fields. So we can try to eliminate this columns of the analysis.

#Build of the dataset

> colnames_training=colnames(df_training)
> colnames_testing=colnames(df_testing)
> newcol=c()
> for (i in 1:length(df_training)) {if (colNA[i] == 0) {newcol= c(newcol,colnames_training[i])}}
> df_training <- df_training[,(names(df_training) %in% newcol)]

We apply the same traitement processing for the data test

> df_testing <- df_testing[,(names(df_testing) %in% newcol)]

Finally, we exclude the 7 first colums of the 2 datasets. They correspond to identification varaibles and they haven't explanatory power.

> df_training <- df_training[,8:length(df_training)]
> df_testing <- df_testing[,8:length(df_testing)]

> colnames(df_training)
 [1] "roll_belt"            "pitch_belt"           "yaw_belt"             "total_accel_belt"    
 [5] "gyros_belt_x"         "gyros_belt_y"         "gyros_belt_z"         "accel_belt_x"        
 [9] "accel_belt_y"         "accel_belt_z"         "magnet_belt_x"        "magnet_belt_y"       
[13] "magnet_belt_z"        "roll_arm"             "pitch_arm"            "yaw_arm"             
[17] "total_accel_arm"      "gyros_arm_x"          "gyros_arm_y"          "gyros_arm_z"         
[21] "accel_arm_x"          "accel_arm_y"          "accel_arm_z"          "magnet_arm_x"        
[25] "magnet_arm_y"         "magnet_arm_z"         "roll_dumbbell"        "pitch_dumbbell"      
[29] "yaw_dumbbell"         "total_accel_dumbbell" "gyros_dumbbell_x"     "gyros_dumbbell_y"    
[33] "gyros_dumbbell_z"     "accel_dumbbell_x"     "accel_dumbbell_y"     "accel_dumbbell_z"    
[37] "magnet_dumbbell_x"    "magnet_dumbbell_y"    "magnet_dumbbell_z"    "roll_forearm"        
[41] "pitch_forearm"        "yaw_forearm"          "total_accel_forearm"  "gyros_forearm_x"     
[45] "gyros_forearm_y"      "gyros_forearm_z"      "accel_forearm_x"      "accel_forearm_y"     
[49] "accel_forearm_z"      "magnet_forearm_x"     "magnet_forearm_y"     "magnet_forearm_z"    
[53] "classe"    

Except the variable income "classe", the dataset testing have the same variables.
After the cross-validation, we will verify if somme variables are constant in each sample.

3. PRE-PROCESSING AND ALGORYTHM

With 19622 observations, the processus could be very long. Furthermore, the data test is very small (20 observations). I divised the actual Training set in a new training set (60%) and a new testing set.
# build small sample for cross-validation

> inTrain <- createDataPartition(y=df_training$classe, p=0.6, list=FALSE)
> df_small_training <- df_training[inTrain,]
> df_small_testing <- df_training[-inTrain,]

We verify on this 2 samples if some variables are constant altought the sample stay very large.

> nsv <- nearZeroVar(df_small_training, saveMetrics=TRUE)

The test is False for all the variables in this sample.
Idem for the small testing sample.
The income variable is categorial so we test the random forest model which combines which combines the concepts of random in space and bagging.

# With standardisation
> set.seed(1000)
> modFit <- train(df_small_training$classe ~ ., method="rf", preProcess=c("center", "scale"), data=df_small_training)

4. RESULTS



